from pyspark.sql import SparkSession
from pyspark.sql import functions as F

#Initializing the spark session 
spark = SparkSession.builder.appName("Dmart Analysis").getOrCreate()

#loading the data into dataframes
product_df = spark.read.csv("sources/Product.csv", header = True, inferSchema = True)
sales_df = spark.read.csv("sources/Sales.csv", header = True, inferSchema = True)
customer_df = spark.read.csv("sources/Customer.csv", header = True, inferSchema = True)

#Renaming the Column
product_df = product_df.withColumnRenamed('Product ID','product_id').withColumnRenamed('Product Name','product_name').withColumnRenamed('Category','category').withColumnRenamed('Sub-Category','sub_category')

sales_df = sales_df.withColumnRenamed('Order Line','order_line').withColumnRenamed('Order ID','order_id').withColumnRenamed('Order Date','order-date').withColumnRenamed('Ship Date','ship_date').withColumnRenamed('Ship Mode','ship_mode').withColumnRenamed('Customer ID','customer_id').withColumnRenamed('Product ID','product_id')

customer_df = customer_df.withColumnRenamed('Customer ID','customer_id').withColumnRenamed('Customer Name','customer_name').withColumnRenamed('Postal Code','postal_code')

#dropping null values
customer_df = customer_df.dropna(subset =["customer_id"])
product_df = product_df.dropna(subset =["product_id"])
sales_df = sales_df.dropna(subset =['order_id'])

#joining the dataframes
sales_products_df = sales_df.join(product_df, on="product_id", how="inner")
full_df = sales_products_df.join(customer_df, on="customer_id", how="inner")

#writing the data into csv
full_df.write.csv("./transformed_csv",header = True, mode="overwrite")

#loading the data into table
full_df.createOrReplaceTempView("sales")

#Analytical Questions
# 1. What is the total sales revenue generated by each customer segment (Consumer, Corporate, Home Office)?

segment_sales = spark.sql("""
    SELECT Segment, ROUND(SUM(Sales), 2) as Total_Sales
    FROM sales
    GROUP BY Segment
    ORDER BY Total_Sales DESC
""")
print("Total Sales generated by Customer Segment")
segment_sales.show()

# 2. Which product sub-category contributes the highest profit overall, and which contributes the lowest?

profit_by_subcat = spark.sql("""
    SELECT sub_category, ROUND(SUM(Profit), 2) as Total_Profit
    FROM sales
    GROUP BY sub_category
    ORDER BY Total_Profit DESC
""")
print("Product sub-category with highest and lowest total profit")
profit_by_subcat.show()

# 3. How does the average discount impact profit margins across different product categories (Furniture, Office Supplies, Technology)?

discount_impact = spark.sql("""
    SELECT category, ROUND(AVG(Discount), 2) as Avg_Discount, ROUND(AVG(Profit), 2) as Avg_Profit
    FROM sales
    GROUP BY category
    ORDER BY category
""")
print("Average discount impact on profit margins across categories")
discount_impact.show()

# 4. Which region has the highest total sales and which has the lowest?

region_sales = spark.sql("""
    SELECT Region, ROUND(SUM(Sales), 2) as Total_Sales
    FROM sales
    GROUP BY Region
    ORDER BY Total_Sales DESC
""")
print("Region with highest and lowest total sales")
region_sales.show()

# 5. Which customer segment (Consumer, Corporate, Home Office) generates the highest total profit, and how does the average discount offered vary across these segments?

customer_segment = spark.sql("""
      SELECT 
    Segment,
    ROUND(SUM(Profit), 2) AS total_profit,
    ROUND(AVG(Discount), 2) AS avg_discount
    FROM sales
    GROUP BY Segment
    ORDER BY total_profit DESC
""")
print("Customer segment (Consumer, Corporate, Home Office) generates the highest total profit")
customer_segment.show()

#6. What is the average order quantity per product category, and how does it affect total sales and profit?

category_qty = spark.sql("""
    SELECT category,
           ROUND(AVG(Quantity), 2) as Avg_Quantity,
           ROUND(SUM(Sales), 2) as Total_Sales,
           ROUND(SUM(Profit), 2) as Total_Profit
    FROM sales
    GROUP BY category
    ORDER BY category
""")
print("Average order quantity per product category and effect on sales and profit")
category_qty.show()

#7. Are there specific customers or customer IDs who consistently generate negative profit, and what products are associated with those orders?

negative_profit_customers = spark.sql("""
    SELECT customer_id, customer_name, product_name, Profit
    FROM sales
    WHERE Profit < 0
    ORDER BY Profit
""")
print("Customers or IDs with consistently negative profit and associated products")
negative_profit_customers.show()

#8. How does customer age relate to sales volume and profit? Do certain age groups buy more or generate higher profits?

age_sales_profit = spark.sql("""
    SELECT Age,
           ROUND(SUM(Sales), 2) as Total_Sales,
           ROUND(SUM(Profit), 2) as Total_Profit,
           COUNT(*) as Number_of_Orders
    FROM sales
    GROUP BY Age
    ORDER BY Age
""")
print("Customer age relation to sales volume and profit")
age_sales_profit.show()

#9 .Which cities or states show the highest sales volume for the Technology category?

tech_sales_city = spark.sql("""
    SELECT City, State, ROUND(SUM(Sales), 2) as Tech_Sales
    FROM sales
    WHERE category = 'Technology'
    GROUP BY City, State
    ORDER BY Tech_Sales DESC
    LIMIT 10
""")
print("Cities or states with highest sales in Technology category")
tech_sales_city.show()

#10. What is the impact of high discount rates (e.g., 20% or more) on sales and profit across different product sub-categories?

high_discount_impact = spark.sql("""
    SELECT sub_category,
           ROUND(SUM(Sales), 2) as Total_Sales,
           ROUND(SUM(Profit), 2) as Total_Profit,
           COUNT(*) as Num_Orders
    FROM sales
    WHERE Discount >= 0.2
    GROUP BY sub_category
    ORDER BY Total_Profit DESC
""")
print("Impact of high discounts (20% or more) on sales and profit by sub-category")
high_discount_impact.show()


# 1. What is the total sales for each product category?

print("Total sales for each product category")
full_df.groupBy("category").agg(F.sum("Sales").alias("Total_Sales")).show()

# 2. Which customer has made the highest number of purchases?

print("Customer with the highest number of purchases")
full_df.groupBy("customer_id").agg(F.count("order_ID").alias("Num_Purchases")) \
    .orderBy(F.desc("Num_Purchases")).limit(1).show()

# 3. What is the average discount given on sales across all products?

print("Average discount given on sales across all products")
full_df.agg(F.avg("Discount").alias("Average_Discount")).show()

# 4. How many unique products were sold in each region?

print("Unique products sold in each region")
full_df.groupBy("Region").agg(F.countDistinct("product_id").alias("Unique_Products_Sold")).show()

# 5. What is the total profit generated in each state?

print("Total profit generated in each state")
full_df.groupBy("State").agg(F.sum("Profit").alias("Total_Profit")).show()

# 6. Which product sub-category has the highest sales?

print("Product sub-category with the highest sales")
full_df.groupBy("sub_category").agg(F.sum("Sales").alias("Total_Sales")) \
    .orderBy(F.desc("Total_Sales")).limit(1).show()

# 7.What is the average age of customers in each segment?

print("Average age of customers in each segment")
full_df.groupBy("Segment").agg(F.avg("Age").alias("Average_Age")).show()

# 8.How many orders were shipped in each shipping mode?

print("Orders shipped in each shipping mode")
full_df.groupBy("ship_mode").agg(F.count("order_id").alias("Total_Shipped")).show()

# 9.What is the total quantity of products sold in each city?

print("Total quantity of products sold in each city")
full_df.groupBy("City").agg(F.sum("Quantity").alias("Total_Quantity_Sold")).show()

# 10.Which customer segment has the highest profit margin?

print("Customer segment with the highest profit margin")
full_df = full_df.withColumn("Profit_Margin", F.col("Profit") / F.col("Sales"))
full_df.groupBy("Segment").agg(F.avg("Profit_Margin").alias("Avg_Profit_Margin")) \
    .orderBy(F.desc("Avg_Profit_Margin")).limit(1).show()



